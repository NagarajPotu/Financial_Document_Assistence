ğŸ“Š Financial Document Q&A App using Streamlit + Ollama

This is a beginner-friendly Streamlit web app that allows you to upload PDF or Excel financial documents and ask questions about them using a local AI model running with Ollama
.

Everything runs entirely on your computer â€” no internet-based LLMs (like OpenAI) are required.

ğŸ§  What Does This App Do?

You upload a PDF or Excel file (e.g., a financial report, bank statement, budget sheet)

The app extracts the content from the file

You can then ask questions in plain English, like:

"What was the total revenue in 2022?"

"Which month had the highest expense?"

The app sends this context + your question to a local language model (like LLaMA3) using Ollama

ğŸ–¥ï¸ Demo Screenshot

<img width="1835" height="963" alt="image" src="https://github.com/user-attachments/assets/bbdbad1d-71a6-40a7-96f1-9b8d213b3ccd" />


ğŸ“¦ Project Structure
financial-qa-app/
â”œâ”€â”€ app.py             # Main Streamlit app
â”œâ”€â”€ extractor.py       # PDF and Excel data extractors
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ README.md          # You're reading it!

ğŸ› ï¸ Requirements

Before you begin, make sure you have:

âœ… A laptop with Windows / macOS / Ubuntu

âœ… Python 3.10+ installed

âœ… Ollama installed for running the LLM locally

âœ… A modern browser (Chrome, Firefox, etc.)

ğŸ Step 1: Install Python (if not installed)

ğŸ”— Download Python 3.10+

During installation, check the box that says "Add Python to PATH"

ğŸ§  Step 2: Install Ollama (Local AI Model)

Ollama is a tool that lets you run language models (like LLaMA 3) on your own machine.

ğŸ§‘â€ğŸ’» Download Ollama:

ğŸ”— https://ollama.com/download

Install it for your OS and then open a terminal and run:

ollama run llama3
(This command will download the LLaMA 3 model (~4â€“5GB). You only need to do this once.)

Keep this terminal open in the background â€” it starts a local API server at http://localhost:11434.

ğŸ’» Step 3: Clone or Download the Project

You can either:

ğŸ“¥ Option A: Download ZIP

Click the green "Code" button on GitHub

Click "Download ZIP"

Extract the ZIP file to a folder

ğŸ’¡ Option B: Use Git (Recommended)
git clone https://github.com/yourusername/financial-qa-app.git
cd financial-qa-app

ğŸ§° Step 4: Set Up Virtual Environment (Optional but Recommended)
# Create a virtual environment
python -m venv venv

# Activate it:
# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate

ğŸ“¦ Step 5: Install Required Python Libraries

Make sure you're in the project folder (financial-qa-app) and run:

pip install -r requirements.txt


This installs:

streamlit

requests

pandas

pdfplumber

openpyxl (for reading Excel files)

ğŸš€ Step 6: Run the App

Start your Ollama model in one terminal:

ollama run llama3


Then, in another terminal, run your Streamlit app:

streamlit run app.py


This will open a browser window at:

http://localhost:8501


You can now:

Upload a PDF or Excel file

Ask a question about its contents

Get AI-powered answers instantly â€” all locally!

ğŸ§  Example Questions to Try

"What is the net profit in this file?"

"Summarize the balance sheet."

"Which department had the highest expenses?"

ğŸ“ Supported File Types

.pdf

.xlsx, .xls (Excel)

ğŸ›‘ Common Issues
Issue	Solution
ModuleNotFoundError	Run pip install -r requirements.txt inside your virtual env
WinError 10061 (Ollama connection)	Make sure ollama run llama3 is running before the app
PDF returns empty text	Some PDFs are scanned images â€” use OCR or better PDFs
App doesn't open in browser	Manually go to http://localhost:8501 in your browser
ğŸ™‹ FAQ
ğŸ”¹ Do I need an internet connection?

Only for the first time when downloading the model via Ollama. After that, it runs fully offline.

ğŸ”¹ Is it free?

Yes â€” no API keys, no cloud hosting, everything runs locally.

ğŸ”¹ Can I deploy this online?

Not with Ollama by default, since it requires a local model. Youâ€™d need a server running Ollama for public access.

ğŸ“œ License

This project is open-source and free to use. Attribution appreciated.

ğŸ¤ Contributing

Feel free to fork the project and submit a pull request if you'd like to improve or extend it!

ğŸ‘¨â€ğŸ’» Made with â¤ï¸ using Streamlit + Ollama

ğŸ“§ Contact

Created by Nagaraj Potu

ğŸ“© Email: nagarajpotu@gmail.com
